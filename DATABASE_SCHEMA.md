# Resume Intelligence Database Schema

This document summarizes the MongoDB collections used by the Resume Intelligence platform. Share it with stakeholders to explain what is stored, how records relate, and which indexes support performance.

## Collections Overview

| Collection | Purpose |
|------------|---------|
| `users` | Stores registered platform users and their authentication state.
| `resumes` | Primary store for uploaded resume metadata, parsed content, and NLP attributes.
| `analyses` | AI-driven scoring and analysis artifacts linked to resumes.
| `feedback` | End user feedback on specific resume analyses.
| `ontology` | Master lists of skills, job titles, and industries used for enrichment.
| `analysis_settings` | Personalized analysis preferences and saved job descriptions per user.

## `users` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | ObjectId | Primary key generated by MongoDB. |
| `name` | string | Full name supplied during registration. |
| `email` | string | Lowercased email address. Unique index enforced. |
| `password` | string | SHA-256 hash with static salt (see `auth.hash_password`). |
| `token` | string or null | Session token minted at login for quick verification. Indexed for lookups. |
| `created_at` | string (ISO 8601) | Registration timestamp. |
| `updated_at` | string (ISO 8601) | Last profile or token change. |

**Indexes**
- `email` unique
- `token`

## `resumes` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | ObjectId | Primary key for the resume document. |
| `filename` | string | Original file name provided by the user. |
| `file_type` | string | Normalized extension (`pdf`, `docx`, `txt`). |
| `upload_date` | datetime | UTC timestamp when upload completed. |
| `file_size` | int | Raw size in bytes. |
| `file_path` | string | Absolute path on the server used for storage. |
| `parsed_text` | string | Full extracted text used for analysis. |
| `masked_text` | string | Anonymized variant for AI prompts. |
| `skills` | array of string | Skills detected by NLP pipeline. |
| `experience_years` | float | Estimated total years of experience. |
| `education` | array of string | Extracted education snippets. |
| `is_duplicate` | bool | True when matched against an existing resume. |
| `duplicate_of` | string or null | Resume `_id` that this upload duplicates. |

**Indexes**
- `filename`
- `upload_date`
- `is_best` (reserved for quick lookups when a resume is marked as best; present for forward compatibility)

## `analyses` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | ObjectId | Primary key for the analysis document. |
| `resume_id` | string | Foreign key referencing `resumes._id` (stored as a string). |
| `filename` | string | Convenience copy of the resume file name. |
| `component_scores` | object | Breakdown of ATS metrics (skill_match, experience, education, format, keyword_density, timeline). |
| `gemini_analysis` | object | Full Gemini response including ATS score, match percentage, keyword analysis, section analysis, strengths, weaknesses, recommendations. |
| `created_at` | datetime | Timestamp when analysis was generated. |
| `is_best` | bool | Marks the analysis that represents the current top resume. |

**Indexes**
- `resume_id`
- `created_at`
- `is_best`

## `feedback` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | ObjectId | Primary key for feedback entry. |
| `resume_id` | string | References the related resume (`resumes._id`). |
| `feedback_text` | string | Free-form comments from the reviewer. |
| `rating` | int | Star rating from 1 to 5. |
| `created_at` | datetime | Submission timestamp. |

## `ontology` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | string | Always `"main"` for the active ontology document. |
| `skills` | array of string | Canonical skill vocabulary. |
| `job_titles` | array of string | Supported job titles used for tagging. |
| `industries` | array of string | Industry taxonomy for enrichment. |
| `updated_at` | datetime | Last update timestamp. |

## `analysis_settings` Collection

| Field | Type | Description |
|-------|------|-------------|
| `_id` | ObjectId | Primary key for the settings document. |
| `user_id` | string | References `users._id` (stored as string). Unique per user. |
| `selected_skills` | array of string | Skill filters the user wants the AI to prioritize. |
| `target_job_title` | string | Preferred job title used to tune analysis prompts. |
| `target_industry` | string | Target industry context for recommendations. |
| `analysis_focus` | string | Explicit focus area (e.g., ATS compatibility, skills alignment). |
| `active_job_description` | object or null | Currently selected job description with `id`, `title`, `company`, `description`, `requirements` (array), `created_at` (ISO string). |
| `job_descriptions` | array of object | Saved job descriptions following the same shape as `active_job_description`. |
| `updated_at` | string (ISO 8601) | Last time the user saved their settings. |

**Indexes**
- `user_id` unique

## Relationships

- `analyses.resume_id` and `feedback.resume_id` reference `resumes._id`. The API uses `ObjectId` strings, so keep types consistent when querying.
- `resumes.duplicate_of` can reference another resume document for deduplication (stored as string). Deleting a resume should cascade manually to associated analyses and feedback (handled in API routes).
- `analysis_settings.user_id` references `users._id`. Each user owns at most one settings document.

## Operational Notes

- All timestamps are stored as UTC. The REST API returns ISO 8601 strings for client consumption.
- Resume files live on disk; the `file_path` field allows background jobs to delete physical files when a resume record is removed.
- Index creation happens during application startup (`database.init_db`). Ensure this job runs once per deployment.
- To export or aggregate data, join `resumes` and `analyses` using the `resume_id` field. For example, pulling ATS results for reporting requires fetching `analyses` and decorating with resume metadata.
